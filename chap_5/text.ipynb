{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa7bdd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messi lập cú đúp trong chiến thắng đậm của Inter Miami\n",
      "MỹTiền đạo Lionel Messi góp công vào cả 5 bàn, gồm cú đúp bàn và cú đúp kiến tạo, giúp Inter Miami thắng Columbus Crew 5-1 ở vòng 17 MLS.\n",
      "Trên sân Lockhart, Fort Lauderdale, Florida hôm 31/5, Messi có màn trình diễn chói sáng. Tiền đạo Argentina đá trọn 90 phút, chạm bóng 69 lần, chuyền chính xác 88% với 5 đường quyết định (key pass), tạo ba cơ hội rõ ràng. Anh được trang Sofascore chấm 10 điểm.\n",
      "\n",
      "Phút 13, Messi chuyền dài để Tadeo Allende xâm nhập vòng cấm rồi sút chéo góc mở tỷ số. Hơn một phút sau, tiền đạo 37 tuổi lập công nhân đôi cách biệt khi nhận món quà từ thủ thành Nicholas Hagen.\n",
      "\n",
      "Nhận bóng trong vòng cấm, Hagen chuyền dài đến đúng vị trí của Messi. Thủ quân Inter Miami hãm bóng bằng ngực rồi cứa lòng chân trái không quá mạnh hướng về khung thành. Hagen tiếp tục mắc lỗi khi đấm bóng về lưới nhà.\n",
      "\n",
      "Phút 24, Sergio Busquets chuyền dài để Messi thoát xuống rồi tâng bóng qua đầu thủ môn Columbus, hoàn tất cú đúp và nâng tỷ số lên 3-0. Busquets và Messi tái hiện màn phối hợp từng \"làm mưa làm gió\" tại Barca.\n",
      "\n",
      "Phút 64, Messi nhận bóng trong vòng cấm rồi chuyền cho Telasco Segovia. Cầu thủ này tiếp tục chuyền ngang cho Luis Suarez sút một chạm về góc gần thành bàn.\n",
      "\n",
      "Messi khép lại ngày thi đấu thăng hoa ở phút 89. Anh chuyền dài để cầu thủ vào sân thay người Fafa Picault xâm nhập vòng cấm rồi đặt lòng về góc gần hạ thủ thành Hagen.\n",
      "\n",
      "Nhờ đó, Messi được bình chọn là cầu thủ hay nhất trận. Lần thứ hai liên tiếp ngôi sao Argentina nhận giải thưởng cá nhân này, sau trận thắng Montreal 4-2 hôm 29/5.\n",
      "\n",
      "Messi chạm mốc 10 bàn tại MLS mùa này, và nâng thành tích lên 31 bàn trong màu áo Inter Miami tại MLS - thành tích tốt nhất lịch sử CLB. Tổng cộng, anh đã có 865 bàn và 384 kiến tạo sau 1.103 trận trong sự nghiệp.\n",
      "\n",
      "Messi góp công vào cả 5 bàn trong trận thắng Columbus Crew.\n",
      "\n",
      "Với chiến thắng 5-1, Inter Miami vươn lên thứ ba MLS miền Đông với 29 điểm, kém Cincinnati một điểm và Philadelphia Union năm điểm, nhưng đá ít hơn một trận.\n",
      "\n",
      "Đây cũng là trận cuối trước khi Inter Miami dự FIFA Club World Cup 2025. Ở vòng bảng, Messi và đồng đội lần lượt gặp Al Ahly ngày 15/6, Porto 20/6 và Palmeiras 24/6.\n",
      "\n",
      "Hồng Duy\n"
     ]
    }
   ],
   "source": [
    "# Read txt\n",
    "with open('Messi.txt', 'r') as file:\n",
    "    text = file.read()\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0da3f669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Messi lập cú đúp trong chiến thắng đậm của Inter Miami\n",
      "\n",
      "\n",
      "\n",
      "(Mỹ) Tiền đạo Lionel Messi góp công vào cả 5 bàn, gồm cú đúp bàn và cú đúp kiến tạo, giúp Inter Miami thắng Columbus Crew 5-1 ở vòng 17 MLS.\n",
      "\n",
      "Trên sân Lockhart, Fort Lauderdale, Florida hôm 31/5, Messi có màn trình diễn chói sáng. Tiền đạo Argentina đá trọn 90 phút, chạm bóng 69 lần, chuyền chính xác 88% với 5 đường quyết định (key pass), tạo ba cơ hội rõ ràng. Anh được trang Sofascore chấm 10 điểm.\n",
      "\n",
      "\n",
      "\n",
      "Phút 13, Messi chuyền dài để Tadeo Allende xâm nhập vòng cấm rồi sút chéo góc mở tỷ số. Hơn một phút sau, tiền đạo 37 tuổi lập công nhân đôi cách biệt khi nhận món quà từ thủ thành Nicholas Hagen.\n",
      "\n",
      "\n",
      "\n",
      "Nhận bóng trong vòng cấm, Hagen chuyền dài đến đúng vị trí của Messi. Thủ quân Inter Miami hãm bóng bằng ngực rồi cứa lòng chân trái không quá mạnh hướng về khung thành. Hagen tiếp tục mắc lỗi khi đấm bóng về lưới nhà.\n",
      "\n",
      "\n",
      "\n",
      "Phút 24, Sergio Busquets chuyền dài để Messi thoát xuống rồi tâng bóng qua đầu thủ môn Columbus, hoàn tất cú đúp và nâng tỷ số lên 3-0. Busquets và Messi tái hiện màn phối hợp từng \"làm mưa làm gió\" tại Barca.\n",
      "\n",
      "\n",
      "\n",
      "Phút 64, Messi nhận bóng trong vòng cấm rồi chuyền cho Telasco Segovia. Cầu thủ này tiếp tục chuyền ngang cho Luis Suarez sút một chạm về góc gần thành bàn.\n",
      "\n",
      "\n",
      "\n",
      "Messi khép lại ngày thi đấu thăng hoa ở phút 89. Anh chuyền dài để cầu thủ vào sân thay người Fafa Picault xâm nhập vòng cấm rồi đặt lòng về góc gần hạ thủ thành Hagen.\n",
      "\n",
      "\n",
      "\n",
      "Nhờ đó, Messi được bình chọn là cầu thủ hay nhất trận. Lần thứ hai liên tiếp ngôi sao Argentina nhận giải thưởng cá nhân này, sau trận thắng Montreal 4-2 hôm 29/5.\n",
      "\n",
      "\n",
      "\n",
      "Messi chạm mốc 10 bàn tại MLS mùa này, và nâng thành tích lên 31 bàn trong màu áo Inter Miami tại MLS - thành tích tốt nhất lịch sử CLB. Tổng cộng, anh đã có 865 bàn và 384 kiến tạo sau 1.103 trận trong sự nghiệp.\n",
      "\n",
      "\n",
      "\n",
      "Messi góp công vào cả 5 bàn trong trận thắng Columbus Crew.\n",
      "\n",
      "\n",
      "\n",
      "Với chiến thắng 5-1, Inter Miami vươn lên thứ ba MLS miền Đông với 29 điểm, kém Cincinnati một điểm và Philadelphia Union năm điểm, nhưng đá ít hơn một trận.\n",
      "\n",
      "\n",
      "\n",
      "Đây cũng là trận cuối trước khi Inter Miami dự FIFA Club World Cup 2025. Ở vòng bảng, Messi và đồng đội lần lượt gặp Al Ahly ngày 15/6, Porto 20/6 và Palmeiras 24/6.\n",
      "\n",
      "\n",
      "\n",
      "Hồng Duy\n"
     ]
    }
   ],
   "source": [
    "# Read docx\n",
    "import docx2txt\n",
    "\n",
    "text_docx = docx2txt.process(\"Messi.docx\")\n",
    "print(text_docx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1e98e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unit 15 –Text and document data processing\n",
      "Dr. Binh Nguyen\n",
      "Phenikaa School of Computing\n",
      "binh.nguyenthanh@phenikaa -uni.edu.vnPython Programming for Data Science6/3/2025 2 phenikaa -uni.edu.vnLearning Objectives\n",
      "1. Master Python libraries for text processing\n",
      "2. Learn document parsing techniques\n",
      "3. Implement practical text analysis projects6/3/2025 3 phenikaa -uni.edu.vnWhy Text Processing Matters\n",
      " Data Analysis\n",
      "•Extract insights from unstructured text data\n",
      "•Process social media posts, reviews, and surveys\n",
      " Machine Learning\n",
      "•Prepare text data for NLP models\n",
      "•Enable sentiment analysis and classification tasks\n",
      " Document Management\n",
      "•Automate processing of PDFs and Word documents\n",
      "•Handle multiple file formats efficiently\n",
      " Automation\n",
      "•Build tools for content extraction\n",
      "•Automate text cleaning and data transformation6/3/2025 4 phenikaa -uni.edu.vnEssential Python Libraries\n",
      " Built -in Libraries\n",
      "•re - Regular expressions\n",
      "•string  - String operations\n",
      "•os - File system operations\n",
      " Text Processing\n",
      "•pandas  - Data manipulation\n",
      "•nltk - Natural language toolkit\n",
      "•spacy  - Advanced NLP\n",
      " Document Formats\n",
      "•PyPDF2/pdfplumber  - PDF processing\n",
      "•python -docx  - Word documents\n",
      "•openpyxl  - Excel files Installation:\n",
      "bash\n",
      "pip install  pandas nltk spacy \n",
      "pip install  PyPDF2 pdfplumber python -docx openpyxl \n",
      "pip install  beautifulsoup4 requests6/3/2025 5 phenikaa -uni.edu.vnBasic Text Operations\n",
      "String Manipulation Fundamentals\n",
      "# Basic string operations  \n",
      "text = \" Hello World! This is Python Text Processing. \"  \n",
      "# Cleaning  \n",
      "clean_text = text.strip ().lower () \n",
      "print (clean_text ) \n",
      "# \"hello world! this is python text processing.\"  \n",
      "# Splitting and joining  \n",
      "words = clean_text .split () print (words ) \n",
      "# ['hello', 'world!', 'this', 'is', 'python', 'text', 'processing.’]  \n",
      "# Joining back  \n",
      "rejoined = \" \".join(words ) print (rejoined )Key Operations:\n",
      "•strip() - Remove whitespace\n",
      "•lower()/upper() - Case conversion\n",
      "•split()/join() - Break apart and combine\n",
      "•replace() - Text substitution6/3/2025 6 phenikaa -uni.edu.vnRegular Expressions (Regex)\n",
      "Powerful pattern matching for text processing\n",
      "import  re text = \"Contact us at john@email.com or call (555) 123 -4567\"  \n",
      "# Find email addresses  \n",
      "emails = re.findall (r'\\b[A-Za-z0-9._%+ -]+@[A -Za-z0-9.-]+\\.[A-Z|a-z]{2,} \\b', text) \n",
      "print (emails ) # ['john@email.com’]  \n",
      "# Find phone numbers  \n",
      "phones = re.findall (r'\\(\\d{3}\\)\\s\\d{3}-\\d{4}' , text) \n",
      "print (phones ) # ['(555) 123 -4567’]  \n",
      "# Replace sensitive info  \n",
      "cleaned = re.sub(r'\\b[A-Za-z0-9._%+ -]+@[A -Za-z0-9.-]+\\.[A-Z|a-z]{2,} \\b', '[EMAIL]' , text) \n",
      "print (cleaned ) # \"Contact us at [EMAIL] or call (555) 123 -4567\"Common Patterns:\n",
      "•\\d - Digits\n",
      "•\\w - Word characters\n",
      "•\\s - Whitespace\n",
      "•+ - One or more\n",
      "•* - Zero or more6/3/2025 7 phenikaa -uni.edu.vnReading Different File Types\n",
      "Text Files\n",
      "# Reading plain text files  \n",
      "with  open ('document.txt' , 'r', encoding ='utf-8') as file: \n",
      " content = file.read () \n",
      "# Reading line by line  \n",
      "with  open ('document.txt' , 'r', encoding ='utf-8') as file: \n",
      " for line_num , line in enumerate (file, 1): \n",
      "  print (f\"Line {line_num }: {line.strip ()}\")CSV Files with Pandas\n",
      "import  pandas as pd \n",
      "# Read CSV with text data  \n",
      "df = pd.read_csv (iris.csv’ ) \n",
      "print (df.head ()) \n",
      "# Access text column  \n",
      "reviews = df['review_text' ].tolist ()\n",
      "JSON Files\n",
      "python\n",
      "import  json \n",
      "# Read JSON data  with  open (‘iris.json' , 'r') as file: \n",
      " data = json.load (file)\n",
      "# Extract text from nested structure  \n",
      "texts = [item ['content' ] for item in data ['articles' ]]6/3/2025 8 phenikaa -uni.edu.vnDocument Processing\n",
      "PDF Processing\n",
      "import  pdfplumber \n",
      "# Extract text from PDF  \n",
      "def extract_pdf_text (pdf_path ): \n",
      " text = \"\" \n",
      " with  pdfplumber .open (pdf_path ) as pdf: \n",
      "  for page in pdf.pages : \n",
      "   text += page .extract_text () + \"\\n\" \n",
      " return  text \n",
      "# Usage  \n",
      "pdf_text = extract_pdf_text (Messi.pdf’ ) \n",
      "print (f\"Extracted {len(pdf_text )} characters\" )6/3/2025 9 phenikaa -uni.edu.vnDocument Processing\n",
      "Word Documents\n",
      "from  docx import  Document \n",
      "# Read Word document  \n",
      "def extract_docx_text (docx_path ): \n",
      " doc = Document (docx_path ) text = [] \n",
      " for paragraph in doc.paragraphs : \n",
      "  text.append (paragraph .text) \n",
      " return  '\\n'.join(text) \n",
      "# Usage  \n",
      "word_text = extract_docx_text (Messi.docx' )6/3/2025 10 phenikaa -uni.edu.vnText Cleaning & Preprocessing\n",
      "import  re \n",
      "import  string \n",
      "def clean_text (text): \n",
      " \"\"\"Comprehensive text cleaning function\"\"\"  \n",
      " # Convert to lowercase  \n",
      " text = text.lower () \n",
      " # Remove URLs  \n",
      " text = re.sub(r'http \\S+|www \\S+|https \\S+', '', text, flags =re.MULTILINE ) \n",
      " # Remove email addresses  \n",
      " text = re.sub(r'\\S+@ \\S+', '', text) \n",
      " # Remove punctuation  \n",
      " text = text.translate (str.maketrans ('', '', string .punctuation )) \n",
      " # Remove extra whitespace  \n",
      " text = re.sub(r'\\s+', ' ', text).strip () \n",
      " # Remove numbers (optional)  \n",
      " text = re.sub(r'\\d+', '', text) \n",
      " return  text \n",
      "# Example usage  \n",
      "dirty_text = \"Check out https://example.com! Email: test@email.com. Price: $99.99!!!\"  \n",
      "clean = clean_text (dirty_text ) \n",
      "print (clean ) # \"check out email price\"Common Cleaning Steps:\n",
      "•Remove URLs and email addresses\n",
      "•Handle punctuation and special characters\n",
      "•Normalize whitespace\n",
      "•Convert to consistent case6/3/2025 11 phenikaa -uni.edu.vnText Analysis with NLTK\n",
      "import  nltk \n",
      "from  nltk.tokenize import  word_tokenize , sent_tokenize \n",
      "from  nltk.corpus import  stopwords \n",
      "from  nltk.stem import  PorterStemmer \n",
      "from  collections import  Counter \n",
      "# Download required data (run once)  \n",
      "# nltk.download('punkt’)  \n",
      "# nltk.download('stopwords’)  \n",
      "def analyze_text (text): \n",
      "# T okenization  \n",
      "words = word_tokenize (text.lower ()) \n",
      "sentences = sent_tokenize (text) \n",
      "# Remove stopwords  stop_words = \n",
      "set(stopwords .words ('english’ )) \n",
      "filtered_words = [word for word in words if word not in \n",
      "stop_words ] # Stemming  \n",
      "stemmer = PorterStemmer () \n",
      "stemmed_words = [stemmer .stem (word ) \n",
      "for word in filtered_words ] \n",
      " # Word frequency  \n",
      " word_freq = Counter (filtered_words ) \n",
      " return  { \n",
      "  'word_count' : len(words ),  \n",
      "  'sentence_count' : len(sentences ), \n",
      "  'unique_words' : len(set(words )), \n",
      "  'top_words' : word_freq .most_common (5) \n",
      " } \n",
      "# Example  \n",
      "text = \"Python is amazing for text processing. Text processing \n",
      "with Python is powerful.\"  \n",
      "analysis = analyze_text (text) \n",
      "print (analysis )6/3/2025 12 phenikaa -uni.edu.vnAdvanced Text Processing\n",
      "Text Similarity\n",
      "from  sklearn .feature_extraction .text import  TfidfVectorizer from  \n",
      "sklearn .metrics .pairwise import  cosine_similarity \n",
      "def text_similarity (text1 , text2 ): \n",
      " \"\"\"Calculate similarity between two texts\"\"\"  \n",
      " vectorizer = TfidfVectorizer () \n",
      " tfidf_matrix = vectorizer .fit_transform ([text1 , text2 ]) \n",
      " similarity = cosine_similarity (tfidf_matrix [0:1], tfidf_matrix [1:2]) \n",
      " return  similarity [0][0] \n",
      "# Example  \n",
      "doc1 = \"Python is great for data science\"  \n",
      "doc2 = \"Data science with Python is awesome\"  \n",
      "similarity = text_similarity (doc1 , doc2 ) \n",
      "print (f\"Similarity: {similarity :.3f}\")6/3/2025 13 phenikaa -uni.edu.vnAdvanced Text ProcessingNamed Entity Recognition with spaCy\n",
      "import  spacy \n",
      "# Load English model (install with: python -m spacy download en_core_web_sm)  \n",
      "nlp = spacy .load (\"en_core_web_sm\" ) \n",
      "def extract_entities (text): \n",
      " doc = nlp(text) \n",
      " entities = [] \n",
      " for ent in doc.ents : \n",
      "  entities .append ({\n",
      "    'text' : ent.text, \n",
      "   'label' : ent.label_ , \n",
      "   'description' : spacy .explain (ent.label_ ) \n",
      "  }) \n",
      " return  entities \n",
      "# Example  \n",
      "text = \"Apple Inc. was founded by Steve Jobs in Cupertino, California.\"  \n",
      "entities = extract_entities (text) \n",
      "for entity in entities : \n",
      " print (f\"{entity ['text' ]} -> {entity ['label' ]} ({entity ['description' ]})\")6/3/2025 14 phenikaa -uni.edu.vnBest Practices & Next Steps\n",
      " Best Practices\n",
      "•Always handle encoding (UTF -8)\n",
      "•Use context managers for file handling\n",
      "•Validate input data\n",
      "•Handle errors gracefully\n",
      "•Document your text processing pipeline\n",
      " Performance Tips\n",
      "•Process large files in chunks\n",
      "•Use generators for memory efficiency\n",
      "•Cache compiled regex patterns\n",
      "•Consider parallel processing\n",
      "•Profile your code\n",
      " Next Steps\n",
      "•Explore machine learning with text\n",
      "•Learn about transformers (BERT , GPT)\n",
      "•Build text classification models\n",
      "•Create chatbots and QA systems\n",
      "•Practice with real datasets6/3/2025 15 phenikaa -uni.edu.vnKey Takeaways\n",
      "1.Python offers powerful tools for text processing\n",
      "2.Start with basic operations, then advance to NLP\n",
      "3.Always clean and preprocess your text data\n",
      "4.Practice with real -world projects and datasets6/3/2025 16 phenikaa -uni.edu.vnTHANK YOU!\n"
     ]
    }
   ],
   "source": [
    "# Read pdf\n",
    "import PyPDF2\n",
    "\n",
    "with open('B15 - Xử lý dữ liệu văn bản.pdf', 'rb') as file:\n",
    "    reader = PyPDF2.PdfReader(file)\n",
    "    text_pdf = ''\n",
    "    for page in reader.pages:\n",
    "        text_pdf += page.extract_text()\n",
    "    print(text_pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46894062",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
