{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fed6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import ast\n",
    "\n",
    "def get_rare_tokens(df: pd.DataFrame, threshold: int=2) -> set:\n",
    "    all_sentences = df['tokens'].tolist()\n",
    "    all_tokens = [token for sentence in all_sentences for token in sentence]\n",
    "    token_counts = Counter(all_tokens)\n",
    "    rare_tokens = {token for token, count in token_counts.items() if count < threshold}\n",
    "    return rare_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78f342cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>dataset</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slide giáo trình đầy đủ .</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>[slide, giáo_trình, đầy_đủ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nhiệt tình giảng dạy , gần gũi với sinh viên .</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>[nhiệt_tình, giảng_dạy, gần_gũi, sinh_viên]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>đi học đầy đủ full điểm chuyên cần .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[đi, học, đầy_đủ, full, chuyên_cần]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chưa áp dụng công nghệ thông tin và các thiết ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[áp_dụng, công_nghệ, thông_tin, thiết_bị, giản...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thầy giảng bài hay , có nhiều bài tập ví dụ ng...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>[thầy, giảng, bài_tập, ví_dụ, lớp]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  topic  sentiment   \n",
       "0                          slide giáo trình đầy đủ .      1          2  \\\n",
       "1     nhiệt tình giảng dạy , gần gũi với sinh viên .      0          2   \n",
       "2               đi học đầy đủ full điểm chuyên cần .      1          0   \n",
       "3  chưa áp dụng công nghệ thông tin và các thiết ...      0          0   \n",
       "4  thầy giảng bài hay , có nhiều bài tập ví dụ ng...      0          2   \n",
       "\n",
       "  dataset                                             tokens  \n",
       "0   train                        [slide, giáo_trình, đầy_đủ]  \n",
       "1   train        [nhiệt_tình, giảng_dạy, gần_gũi, sinh_viên]  \n",
       "2   train                [đi, học, đầy_đủ, full, chuyên_cần]  \n",
       "3   train  [áp_dụng, công_nghệ, thông_tin, thiết_bị, giản...  \n",
       "4   train                 [thầy, giảng, bài_tập, ví_dụ, lớp]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/preprocessed_data.csv\")\n",
    "df['tokens'] = df['tokens'].apply(ast.literal_eval)\n",
    "\n",
    "df_train = df[df['dataset'] == 'train']\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c3be5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rare tokens is: 1623\n",
      "Some rare tokens are: ['ngang', 'ht1', 'wzjwz37', 'thoại', 'max']\n"
     ]
    }
   ],
   "source": [
    "rare_tokens = get_rare_tokens(df_train, 2)\n",
    "\n",
    "print(f\"The number of rare tokens is: {len(rare_tokens)}\")\n",
    "print(f\"Some rare tokens are: {list(rare_tokens)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ab81880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vocabulary size is: 1697\n"
     ]
    }
   ],
   "source": [
    "vocab = {\"<PAD>\": 0, \"<UNK>\": 1}\n",
    "for token in df_train['tokens'].explode().unique():\n",
    "    if token not in rare_tokens:\n",
    "        vocab[token] = len(vocab)\n",
    "print(f\"The vocabulary size is: {len(vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5d67fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>topic</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>dataset</th>\n",
       "      <th>tokens</th>\n",
       "      <th>input_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>slide giáo trình đầy đủ .</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>[slide, giáo_trình, đầy_đủ]</td>\n",
       "      <td>[2, 3, 4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>nhiệt tình giảng dạy , gần gũi với sinh viên .</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>[nhiệt_tình, giảng_dạy, gần_gũi, sinh_viên]</td>\n",
       "      <td>[5, 6, 7, 8]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>đi học đầy đủ full điểm chuyên cần .</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[đi, học, đầy_đủ, full, chuyên_cần]</td>\n",
       "      <td>[9, 10, 4, 1, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chưa áp dụng công nghệ thông tin và các thiết ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>train</td>\n",
       "      <td>[áp_dụng, công_nghệ, thông_tin, thiết_bị, giản...</td>\n",
       "      <td>[12, 13, 14, 15, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thầy giảng bài hay , có nhiều bài tập ví dụ ng...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>train</td>\n",
       "      <td>[thầy, giảng, bài_tập, ví_dụ, lớp]</td>\n",
       "      <td>[16, 17, 18, 19, 20]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  topic  sentiment   \n",
       "0                          slide giáo trình đầy đủ .      1          2  \\\n",
       "1     nhiệt tình giảng dạy , gần gũi với sinh viên .      0          2   \n",
       "2               đi học đầy đủ full điểm chuyên cần .      1          0   \n",
       "3  chưa áp dụng công nghệ thông tin và các thiết ...      0          0   \n",
       "4  thầy giảng bài hay , có nhiều bài tập ví dụ ng...      0          2   \n",
       "\n",
       "  dataset                                             tokens   \n",
       "0   train                        [slide, giáo_trình, đầy_đủ]  \\\n",
       "1   train        [nhiệt_tình, giảng_dạy, gần_gũi, sinh_viên]   \n",
       "2   train                [đi, học, đầy_đủ, full, chuyên_cần]   \n",
       "3   train  [áp_dụng, công_nghệ, thông_tin, thiết_bị, giản...   \n",
       "4   train                 [thầy, giảng, bài_tập, ví_dụ, lớp]   \n",
       "\n",
       "              input_ids  \n",
       "0             [2, 3, 4]  \n",
       "1          [5, 6, 7, 8]  \n",
       "2     [9, 10, 4, 1, 11]  \n",
       "3   [12, 13, 14, 15, 6]  \n",
       "4  [16, 17, 18, 19, 20]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Properly map unknown tokens to <UNK>, not <PAD>\n",
    "def encode(tokens):\n",
    "    return [vocab.get(tok, vocab[\"<UNK>\"]) for tok in tokens]\n",
    "\n",
    "df['input_ids'] = df['tokens'].apply(encode)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f08e3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def split_dataset(label_column):\n",
    "    df_train = df[df['dataset'] == 'train']\n",
    "    df_val = df[df['dataset'] == 'valid']\n",
    "    df_test = df[df['dataset'] == 'test']\n",
    "\n",
    "    def prepare(df_split):\n",
    "        X = [torch.tensor(seq) for seq in df_split['input_ids']]\n",
    "        y = df_split[label_column].tolist()\n",
    "        return X, y\n",
    "\n",
    "    X_train, y_train = prepare(df_train)\n",
    "    X_val, y_val = prepare(df_val)\n",
    "    X_test, y_test = prepare(df_test)\n",
    "\n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f898420",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, sequences, labels):\n",
    "        self.sequences = pad_sequence(sequences, batch_first=True, padding_value=vocab[\"<PAD>\"])\n",
    "        self.labels = torch.tensor(labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sequences[idx], self.labels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2752ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as f\n",
    "\n",
    "class LSTMClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_dim, hidden_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(emb_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, out_dim)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        _, (h, _) = self.lstm(x)\n",
    "        return self.fc(self.dropout(h[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c5f1b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, epochs=50, patience=5):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "    wait = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for x, y in train_loader:\n",
    "            opt.zero_grad()\n",
    "            out = model(x)\n",
    "            loss = loss_fn(out, y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        model.eval()\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for x, y in val_loader:\n",
    "                out = model(x)\n",
    "                total += loss_fn(out, y).item()\n",
    "        avg = total / len(val_loader)\n",
    "        print(f\"Epoch {epoch+1}, val loss: {avg:.4f}\")\n",
    "\n",
    "        if avg < best_loss:\n",
    "            best_loss = avg\n",
    "            best_state = model.state_dict()\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "            if wait >= patience:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(best_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b37c252",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            out = model(x)\n",
    "            pred = out.argmax(dim=1)\n",
    "            all_preds.extend(pred.tolist())\n",
    "            all_labels.extend(y.tolist())\n",
    "    print(classification_report(all_labels, all_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "13926be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def run_for_task(label_column, **kwargs):\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test) = split_dataset(label_column)\n",
    "\n",
    "    train_ds = TextDataset(X_train, y_train)\n",
    "    val_ds = TextDataset(X_val, y_val)\n",
    "    test_ds = TextDataset(X_test, y_test)\n",
    "\n",
    "    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_ds, batch_size=32)\n",
    "    test_loader = DataLoader(test_ds, batch_size=32)\n",
    "\n",
    "    model = LSTMClassifier(\n",
    "        vocab_size=len(vocab),\n",
    "        emb_dim=128,\n",
    "        hidden_dim=64,\n",
    "        out_dim=len(set(y_train + y_val + y_test)),\n",
    "    )\n",
    "\n",
    "    epochs = kwargs.get(\"epochs\", 50)\n",
    "    patience = kwargs.get(\"patience\", epochs // 10)\n",
    "\n",
    "    train_model(model, train_loader, val_loader, epochs=epochs, patience=patience)\n",
    "    evaluate_model(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d75020d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, val loss: 0.6558\n",
      "Epoch 2, val loss: 0.6688\n",
      "Epoch 3, val loss: 0.5831\n",
      "Epoch 4, val loss: 0.5859\n",
      "Epoch 5, val loss: 0.5211\n",
      "Epoch 6, val loss: 0.5032\n",
      "Epoch 7, val loss: 0.4869\n",
      "Epoch 8, val loss: 0.5183\n",
      "Epoch 9, val loss: 0.5255\n",
      "Epoch 10, val loss: 0.4775\n",
      "Epoch 11, val loss: 0.5633\n",
      "Epoch 12, val loss: 0.5058\n",
      "Epoch 13, val loss: 0.5393\n",
      "Epoch 14, val loss: 0.5257\n",
      "Epoch 15, val loss: 0.5145\n",
      "Epoch 16, val loss: 0.5614\n",
      "Epoch 17, val loss: 0.5253\n",
      "Epoch 18, val loss: 0.5351\n",
      "Epoch 19, val loss: 0.5783\n",
      "Epoch 20, val loss: 0.5609\n",
      "Early stopping\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.87      0.90      2290\n",
      "           1       0.52      0.77      0.62       572\n",
      "           2       0.73      0.92      0.81       145\n",
      "           3       0.15      0.01      0.02       159\n",
      "\n",
      "    accuracy                           0.81      3166\n",
      "   macro avg       0.59      0.64      0.59      3166\n",
      "weighted avg       0.81      0.81      0.80      3166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_for_task(\"topic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8448abd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, val loss: 0.8459\n",
      "Epoch 2, val loss: 0.8462\n",
      "Epoch 3, val loss: 0.8455\n",
      "Epoch 4, val loss: 0.8466\n",
      "Epoch 5, val loss: 0.8456\n",
      "Epoch 6, val loss: 0.8454\n",
      "Epoch 7, val loss: 0.8459\n",
      "Epoch 8, val loss: 0.8456\n",
      "Epoch 9, val loss: 0.8457\n",
      "Epoch 10, val loss: 0.8465\n",
      "Epoch 11, val loss: 0.8453\n",
      "Epoch 12, val loss: 0.8457\n",
      "Epoch 13, val loss: 0.8453\n",
      "Epoch 14, val loss: 0.8457\n",
      "Epoch 15, val loss: 0.8457\n",
      "Epoch 16, val loss: 0.8452\n",
      "Epoch 17, val loss: 0.8390\n",
      "Epoch 18, val loss: 0.8358\n",
      "Epoch 19, val loss: 0.8326\n",
      "Epoch 20, val loss: 0.8399\n",
      "Epoch 21, val loss: 0.8372\n",
      "Epoch 22, val loss: 0.8338\n",
      "Epoch 23, val loss: 0.8344\n",
      "Epoch 24, val loss: 0.8377\n",
      "Epoch 25, val loss: 0.8349\n",
      "Epoch 26, val loss: 0.8345\n",
      "Epoch 27, val loss: 0.8340\n",
      "Epoch 28, val loss: 0.8370\n",
      "Epoch 29, val loss: 0.8344\n",
      "Epoch 30, val loss: 0.8351\n",
      "Epoch 31, val loss: 0.8350\n",
      "Epoch 32, val loss: 0.8349\n",
      "Epoch 33, val loss: 0.8351\n",
      "Epoch 34, val loss: 0.8339\n",
      "Epoch 35, val loss: 0.8355\n",
      "Epoch 36, val loss: 0.8359\n",
      "Epoch 37, val loss: 0.8356\n",
      "Epoch 38, val loss: 0.8357\n",
      "Epoch 39, val loss: 0.8357\n",
      "Epoch 40, val loss: 0.8372\n",
      "Epoch 41, val loss: 0.8359\n",
      "Epoch 42, val loss: 0.8359\n",
      "Epoch 43, val loss: 0.8370\n",
      "Epoch 44, val loss: 0.8361\n",
      "Epoch 45, val loss: 0.8351\n",
      "Epoch 46, val loss: 0.8347\n",
      "Epoch 47, val loss: 0.8362\n",
      "Epoch 48, val loss: 0.8316\n",
      "Epoch 49, val loss: 0.8319\n",
      "Epoch 50, val loss: 0.8313\n",
      "Epoch 51, val loss: 0.8322\n",
      "Epoch 52, val loss: 0.8332\n",
      "Epoch 53, val loss: 0.8314\n",
      "Epoch 54, val loss: 0.8315\n",
      "Epoch 55, val loss: 0.8317\n",
      "Epoch 56, val loss: 0.8314\n",
      "Epoch 57, val loss: 0.8327\n",
      "Epoch 58, val loss: 0.8340\n",
      "Epoch 59, val loss: 0.8293\n",
      "Epoch 60, val loss: 0.8308\n",
      "Epoch 61, val loss: 0.8311\n",
      "Epoch 62, val loss: 0.8303\n",
      "Epoch 63, val loss: 0.8302\n",
      "Epoch 64, val loss: 0.8296\n",
      "Epoch 65, val loss: 0.8301\n",
      "Epoch 66, val loss: 0.8333\n",
      "Epoch 67, val loss: 0.8315\n",
      "Epoch 68, val loss: 0.8239\n",
      "Epoch 69, val loss: 0.8269\n",
      "Epoch 70, val loss: 0.8166\n",
      "Epoch 71, val loss: 0.8126\n",
      "Epoch 72, val loss: 0.8087\n",
      "Epoch 73, val loss: 0.7767\n",
      "Epoch 74, val loss: 0.7612\n",
      "Epoch 75, val loss: 0.7417\n",
      "Epoch 76, val loss: 0.7332\n",
      "Epoch 77, val loss: 0.8480\n",
      "Epoch 78, val loss: 0.8467\n",
      "Epoch 79, val loss: 0.8461\n",
      "Epoch 80, val loss: 0.8468\n",
      "Epoch 81, val loss: 0.8456\n",
      "Epoch 82, val loss: 0.8456\n",
      "Epoch 83, val loss: 0.8470\n",
      "Epoch 84, val loss: 0.8456\n",
      "Epoch 85, val loss: 0.8471\n",
      "Epoch 86, val loss: 0.8454\n",
      "Epoch 87, val loss: 0.8491\n",
      "Epoch 88, val loss: 0.8440\n",
      "Epoch 89, val loss: 0.7321\n",
      "Epoch 90, val loss: 0.7351\n",
      "Epoch 91, val loss: 0.7307\n",
      "Epoch 92, val loss: 0.7292\n",
      "Epoch 93, val loss: 0.7284\n",
      "Epoch 94, val loss: 0.7278\n",
      "Epoch 95, val loss: 0.7265\n",
      "Epoch 96, val loss: 0.7255\n",
      "Epoch 97, val loss: 0.7429\n",
      "Epoch 98, val loss: 0.7475\n",
      "Epoch 99, val loss: 0.7382\n",
      "Epoch 100, val loss: 0.7364\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      1409\n",
      "           1       0.00      0.00      0.00       167\n",
      "           2       0.68      0.80      0.74      1590\n",
      "\n",
      "    accuracy                           0.68      3166\n",
      "   macro avg       0.45      0.47      0.46      3166\n",
      "weighted avg       0.64      0.68      0.66      3166\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/lan/.local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "run_for_task(\"sentiment\", epochs=100, patience=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ddcbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
